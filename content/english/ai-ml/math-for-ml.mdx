---
title: "Mathematics for ML"
description: "Linear algebra, calculus, and probability for machine learning."
---

# Mathematics for ML

A solid mathematical foundation is essential for understanding how ML algorithms work under the hood.

## Linear Algebra

Vectors and matrices are the language of machine learning.

```python
import numpy as np

# Matrix multiplication
W = np.random.randn(128, 64)  # Weight matrix
x = np.random.randn(64, 1)    # Input vector
z = W @ x                      # Linear transformation

# Eigendecomposition (used in PCA)
C = np.cov(data.T)
eigenvalues, eigenvectors = np.linalg.eigh(C)

# SVD (used in dimensionality reduction)
U, S, Vt = np.linalg.svd(matrix, full_matrices=False)
```

## Calculus & Optimization

Gradient descent is the core optimization algorithm in ML.

```python
def gradient_descent(f_grad, x0, lr=0.01, epochs=1000):
    x = x0.copy()
    history = []

    for _ in range(epochs):
        grad = f_grad(x)
        x -= lr * grad
        history.append(x.copy())

    return x, history
```

## Probability & Statistics

```python
# Bayes' theorem in practice
def naive_bayes_predict(X, priors, likelihoods):
    posteriors = {}
    for cls in priors:
        log_prob = np.log(priors[cls])
        log_prob += np.sum(np.log(likelihoods[cls].pdf(X)))
        posteriors[cls] = log_prob
    return max(posteriors, key=posteriors.get)
```

> Understanding the math behind algorithms helps you debug models and choose appropriate solutions for your data characteristics.

## Summary

- Linear algebra: vectors, matrices, transformations
- Calculus: gradients, chain rule, optimization
- Probability: Bayes theorem, distributions, sampling
